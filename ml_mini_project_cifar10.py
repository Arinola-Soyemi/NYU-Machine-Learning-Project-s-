# -*- coding: utf-8 -*-
"""ML Mini Project: cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bTcYwxBleaO8MyoQheSFWk5utQpRzX_t
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical

"""### Download the CIFAR10 dataset

The CIFAR10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them.
"""

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

"""### Verify the data

To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image.
"""

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    # The CIFAR labels happen to be arrays,
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

"""Build Model"""

# 0. Prep data
nb_classes = 10
Y_train = to_categorical(train_labels, nb_classes)
Y_test = to_categorical(test_labels, nb_classes)
print("Y_train shape", Y_train.shape)
print("Y_test shape", Y_test.shape)

# 1. Make a model
model = models.Sequential()

model.add(layers.Conv2D(32, (2, 2), input_shape=(32, 32, 3)))
model.add(layers.Conv2D(64, (2, 2)))
model.add(layers.BatchNormalization())
model.add(layers.Activation('relu'))

model.add(layers.Conv2D(128, (2, 2)))
#model.add(layers.Conv2D(128, (2, 2)))
model.add(layers.BatchNormalization())
model.add(layers.Activation('relu'))

model.add(layers.Flatten())
#model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

model.summary()

# 2. Train the model (possibly multiple times with augmented data)
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history1 = model.fit(train_images, Y_train, epochs=18, batch_size=128)

yhat_test = model.predict(test_images)

# 3. Plot the error
# Based off of fish market code from the repo
training_loss1 = history1.history['loss']
plt.plot(training_loss1, label='training loss 1')
#training_loss2 = history2.history['loss']
#plt.plot(training_loss2, label='training loss 2')
plt.xlabel("epochs")
plt.ylabel("training loss")
plt.legend()
plt.grid()

# 4. Print the error

import numpy as np
# 5. Plot y=x, comparing the true values to the predicted values
yhat_test_plot = tf.argmax(yhat_test, axis=1) # source: https://stackoverflow.com/questions/41399481/how-do-you-decode-one-hot-labels-in-tensorflow
y_test_plot = tf.argmax(Y_test, axis=1)
#plt.scatter(yhat_test_plot, y_test_plot)
print(f"accuracy of test set: {np.mean(yhat_test_plot - y_test_plot == 0)}")

# 6. Print out some misclassified images